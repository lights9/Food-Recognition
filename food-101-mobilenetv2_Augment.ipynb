{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n## Food Image Classification\nGiven images of 101 diffrent foods, classify the foods presented in a given image.\nWe will use a TensorFlow/Keras pretrained MobileNetV2 CNN to make our predictions.\n## Getting Started","metadata":{}},{"cell_type":"code","source":"#For working with the data\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport random\n\n#For visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#For preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#For building the model\nimport tensorflow as tf\n\n#For analyzing the performance\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:35:04.857642Z","iopub.execute_input":"2022-07-14T05:35:04.858038Z","iopub.status.idle":"2022-07-14T05:35:04.864688Z","shell.execute_reply.started":"2022-07-14T05:35:04.858007Z","shell.execute_reply":"2022-07-14T05:35:04.863898Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"image_dir = Path('../input/food41/images')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:35:07.514923Z","iopub.execute_input":"2022-07-14T05:35:07.515760Z","iopub.status.idle":"2022-07-14T05:35:07.521020Z","shell.execute_reply.started":"2022-07-14T05:35:07.515712Z","shell.execute_reply":"2022-07-14T05:35:07.520117Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"# Creating File DataFrame\nfor a dataframe to contain one column with all the path files and the other column with all the labels for each image associated with file path","metadata":{}},{"cell_type":"code","source":"filepaths = list(image_dir.glob(r'**/*.jpg'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\n#turns filepaths and labels into panda series and concatenates them into a data frame\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\nimages = pd.concat([filepaths, labels], axis=1) #along axis=1 -> side by side\n\n#there are too many images for this tutorial, therefore we are gone just use 100 imageges\n#for each class\ncategory_samples = []\nfor category in images['Label'].unique():\n    category_slice = images.query(\"Label == @category\")\n    category_samples.append(category_slice.sample(100, random_state=1))\n#axis=0 -> on top of each other; frac=1.0 -> sample 100% of the data without replacement\nimage_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:35:09.758205Z","iopub.execute_input":"2022-07-14T05:35:09.758987Z","iopub.status.idle":"2022-07-14T05:35:12.796316Z","shell.execute_reply.started":"2022-07-14T05:35:09.758940Z","shell.execute_reply":"2022-07-14T05:35:12.795518Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"image_df","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:35:15.202733Z","iopub.execute_input":"2022-07-14T05:35:15.205140Z","iopub.status.idle":"2022-07-14T05:35:15.220028Z","shell.execute_reply.started":"2022-07-14T05:35:15.205093Z","shell.execute_reply":"2022-07-14T05:35:15.219160Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"images.query(\"Label == 'apple_pie'\")","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:35:17.685657Z","iopub.execute_input":"2022-07-14T05:35:17.686032Z","iopub.status.idle":"2022-07-14T05:35:17.704852Z","shell.execute_reply.started":"2022-07-14T05:35:17.686002Z","shell.execute_reply":"2022-07-14T05:35:17.703898Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"image_df['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:35:20.375835Z","iopub.execute_input":"2022-07-14T05:35:20.376232Z","iopub.status.idle":"2022-07-14T05:35:20.389689Z","shell.execute_reply.started":"2022-07-14T05:35:20.376200Z","shell.execute_reply":"2022-07-14T05:35:20.388330Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"## Print random images to see how the data looks like","metadata":{}},{"cell_type":"code","source":"# visualize the training data\nW = 10\nH = 10\nfig, axes = plt.subplots(W, H, figsize = (20,20))\n\naxes = axes.ravel() # flatten the matrix into array\n# Select a random number from 0 to n_training/ images will be selected randomly\nfor i in np.arange(0, W * H): \n    # Select a class randomly\n    label = random.choice(os.listdir(image_dir))\n    class_dir = os.path.join(image_dir,label)\n    # Select a random image\n    image = random.choice(os.listdir(class_dir))\n    # read and display an image with the selected index    \n    img = plt.imread(os.path.join(class_dir,image))\n    axes[i].imshow( img )\n    #print(np.array(img).shape)\n    axes[i].set_title(label, fontsize = 8) # the label\n    axes[i].axis('off')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:37:04.097503Z","iopub.execute_input":"2022-07-14T05:37:04.098439Z","iopub.status.idle":"2022-07-14T05:37:11.904128Z","shell.execute_reply.started":"2022-07-14T05:37:04.098400Z","shell.execute_reply":"2022-07-14T05:37:11.903283Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test Split","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(image_df, train_size=0.8, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:37:19.626445Z","iopub.execute_input":"2022-07-14T05:37:19.626869Z","iopub.status.idle":"2022-07-14T05:37:19.639718Z","shell.execute_reply.started":"2022-07-14T05:37:19.626837Z","shell.execute_reply":"2022-07-14T05:37:19.638572Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"# Creating Generators\nfor loading the images of one batch at a time for not running out of memory","metadata":{}},{"cell_type":"code","source":"# All images will be rescaled by 1./255.\n# Applying some Augmentation\ntrain_datagen = ImageDataGenerator( rescale = 1.0/255.,\n                                  rotation_range=30 ,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  brightness_range=[0.6,1],\n                                  fill_mode='nearest',\n                                  validation_split=0.2)\n\ntest_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:37:25.365220Z","iopub.execute_input":"2022-07-14T05:37:25.365688Z","iopub.status.idle":"2022-07-14T05:37:25.372860Z","shell.execute_reply.started":"2022-07-14T05:37:25.365649Z","shell.execute_reply":"2022-07-14T05:37:25.371473Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"#speciffies which images will be used, then the generator takes images through the\n#data frame, trains on them and recycles them\ntrain_images = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical', #since it is a multi-class classification task\n    batch_size=32,\n    shuffle=True,\n    seed=42, #to reproduce results\n    subset='training' #only available when a validation split is used, specifies if \n                    #20% validation or 80% traing is taken\n)\n\nval_images = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical', #since it is a multi-class classification task\n    batch_size=32,\n    shuffle=True,\n    seed=42, #to reproduce results\n    subset='validation' #only available when a validation split is used, specifies if \n                    #20% validation or 80% traing is taken\n)\n\ntest_images = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical', #since it is a multi-class classification task\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:37:30.242248Z","iopub.execute_input":"2022-07-14T05:37:30.242656Z","iopub.status.idle":"2022-07-14T05:37:35.257880Z","shell.execute_reply.started":"2022-07-14T05:37:30.242624Z","shell.execute_reply":"2022-07-14T05:37:35.256669Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# Print the classes\ntrain_images.class_indices","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:37:37.570910Z","iopub.execute_input":"2022-07-14T05:37:37.571376Z","iopub.status.idle":"2022-07-14T05:37:37.581751Z","shell.execute_reply.started":"2022-07-14T05:37:37.571338Z","shell.execute_reply":"2022-07-14T05:37:37.580823Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"# Visualize after Augmentation","metadata":{}},{"cell_type":"code","source":"# viualize some images after the augmentation\nx_batch, y_batch = next(train_images)\nW = 5\nH = 5\nfig, axes = plt.subplots(W, H, figsize = (17,17))\n\naxes = axes.ravel() # flaten the matrix into array\nfor i in np.arange(0, W * H): #from 0 to 5x5=25\n\n    # Select a random image\n    image = x_batch[i]\n    # read and display an image with the selected index    \n    axes[i].imshow( image )\n    axes[i].set_title(np.argmax(y_batch[i]), fontsize = 8) # the label\n    axes[i].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:37:41.282300Z","iopub.execute_input":"2022-07-14T05:37:41.282757Z","iopub.status.idle":"2022-07-14T05:37:45.017641Z","shell.execute_reply.started":"2022-07-14T05:37:41.282721Z","shell.execute_reply":"2022-07-14T05:37:45.016636Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"### with Transfer Learning using MobileNetV2","metadata":{}},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False, #defines if the final classifaction layer that the original model was trained on will be kept or not;\n    #imagenet has 1000 classes, what we do not want here now, therefore we put our own classifaction layer at the top of the model\n    weights='imagenet',\n    pooling='avg' #ensure the output is one-dimensional\n)\n\npretrained_model.trainable = False #ensures that we don't mess up the original net weight","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:39:13.135453Z","iopub.execute_input":"2022-07-14T05:39:13.135884Z","iopub.status.idle":"2022-07-14T05:39:14.330862Z","shell.execute_reply.started":"2022-07-14T05:39:13.135847Z","shell.execute_reply":"2022-07-14T05:39:14.329809Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:39:18.345601Z","iopub.execute_input":"2022-07-14T05:39:18.345988Z","iopub.status.idle":"2022-07-14T05:39:18.418273Z","shell.execute_reply.started":"2022-07-14T05:39:18.345958Z","shell.execute_reply":"2022-07-14T05:39:18.417045Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy', #categorical_crossentropy, becuase we used Generators\n    metrics=['accuracy'] #accuracy, because multi-class\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=20,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            #when the validation loss stops improving for three consecutive epochs, we'll stop\n            #training and restore the weights from the best epoch\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:39:25.714019Z","iopub.execute_input":"2022-07-14T05:39:25.714439Z","iopub.status.idle":"2022-07-14T06:13:13.222853Z","shell.execute_reply.started":"2022-07-14T05:39:25.714404Z","shell.execute_reply":"2022-07-14T06:13:13.221671Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=1) #verbose=0 ->to not get the loading bar\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2022-07-14T06:13:37.137094Z","iopub.execute_input":"2022-07-14T06:13:37.137507Z","iopub.status.idle":"2022-07-14T06:14:07.381646Z","shell.execute_reply.started":"2022-07-14T06:13:37.137460Z","shell.execute_reply":"2022-07-14T06:14:07.380625Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# Plotting Results\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'green', label='Training acc')\nplt.plot(epochs, val_acc, 'orange', label='Validation acc')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.title('Training and validation accuracy')\nplt.legend()\nfig = plt.figure()\nfig.savefig('acc.png')\n\n\nplt.plot(epochs, loss, 'green', label='Training loss')\nplt.plot(epochs, val_loss, 'orange', label='Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and validation loss')\n\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:12:22.060510Z","iopub.execute_input":"2022-07-14T05:12:22.061465Z","iopub.status.idle":"2022-07-14T05:12:22.556933Z","shell.execute_reply.started":"2022-07-14T05:12:22.061422Z","shell.execute_reply":"2022-07-14T05:12:22.555806Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"predictions = np.argmax(model.predict(test_images), axis=1)\n\ncm = confusion_matrix(test_images.labels, predictions)\nclr = classification_report(test_images.labels, predictions, target_names=test_images.class_indices, zero_division=0)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:12:33.068452Z","iopub.execute_input":"2022-07-14T05:12:33.068874Z","iopub.status.idle":"2022-07-14T05:13:05.576581Z","shell.execute_reply.started":"2022-07-14T05:12:33.068842Z","shell.execute_reply":"2022-07-14T05:13:05.575360Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 30))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks=np.arange(101) + 0.5, labels=test_images.class_indices, rotation=90)\nplt.yticks(ticks=np.arange(101) + 0.5, labels=test_images.class_indices, rotation=0)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:13:22.566451Z","iopub.execute_input":"2022-07-14T05:13:22.566863Z","iopub.status.idle":"2022-07-14T05:13:55.043583Z","shell.execute_reply.started":"2022-07-14T05:13:22.566829Z","shell.execute_reply":"2022-07-14T05:13:55.042476Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T05:14:04.101429Z","iopub.execute_input":"2022-07-14T05:14:04.102162Z","iopub.status.idle":"2022-07-14T05:14:04.108556Z","shell.execute_reply.started":"2022-07-14T05:14:04.102111Z","shell.execute_reply":"2022-07-14T05:14:04.107348Z"},"trusted":true},"execution_count":37,"outputs":[]}]}